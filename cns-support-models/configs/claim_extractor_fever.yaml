experiment_name: claim-extractor-fever

data:
  train_path: data/processed/fever_claim_extractor.jsonl
  eval_path: null
  max_samples: 20000        # FEVER is large; cap if needed
  shuffle: true
  batch_size: 8

model:
  base_model: "meta-llama/Llama-3.1-8B-Instruct"
  adapter_name: "claim-extractor-fever"
  lora:
    r: 16
    alpha: 32
    dropout: 0.05

optimization:
  learning_rate: 1.5e-4
  weight_decay: 0.0
  gradient_clip: 1.0
  epochs: 2

logging:
  eval_every_steps: 500
  save_every_steps: 1000
  wandb_project: null
  notes: "FEVER-based training config; ensure wiki-pages are downloaded."
